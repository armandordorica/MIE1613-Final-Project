{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VFV.TO']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Stocks import Stock\n",
    "from Portfolio import Portfolio\n",
    "import plotter as plot\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import distributions as dt\n",
    "import returns as rt\n",
    "import numpy as np\n",
    "\n",
    "import scipy.stats as stats\n",
    "from prophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "import prophet_helpers as ph\n",
    "\n",
    "\n",
    "\n",
    "def read_yaml(file_name): \n",
    "    with open(file_name) as file:\n",
    "        yaml_data= yaml.safe_load(file)\n",
    "    return yaml_data\n",
    "\n",
    "config = read_yaml('config.yaml')\n",
    "# config['canadian_etfs_parsed']\n",
    "canadian_etfs_parsed = config['canadian_etfs_parsed']\n",
    "canadian_etfs_parsed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Dataset_info.png\" alt=\"Screenshot\" width=\"800\" height='400'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_dates(date1, date2):\n",
    "    date1_obj = datetime.strptime(date1, '%Y-%m-%d')\n",
    "    date2_obj = datetime.strptime(date2, '%Y-%m-%d')\n",
    "    diff = date1_obj - date2_obj\n",
    "    return diff.days\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def subtract_days(date_str, days):\n",
    "    date_obj = datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    new_date_obj = date_obj - timedelta(days=days)\n",
    "    return new_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def subtract_trading_days(date_str, days):\n",
    "    date_obj = pd.to_datetime(date_str)\n",
    "    offset = pd.offsets.BDay(n=days * -1)\n",
    "    new_date_obj = offset.apply(date_obj)\n",
    "    return new_date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/tgqd8prn2x1g474v7zwrxq7r0000gn/T/ipykernel_14411/2576946134.py:1: FutureWarning: BusinessDay.apply is deprecated and will be removed in a future version. Use `offset + other` instead\n",
      "  subtract_trading_days('2012-12-31', 502)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2011-01-27'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtract_trading_days('2012-12-31', 502)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data from alpaca\n",
      "Data from alpaca not available, pulling from yahoo\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "data from alpaca\n",
      "Data from alpaca not available, pulling from yahoo\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "data from alpaca\n",
      "Data from alpaca not available, pulling from yahoo\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "start_dt = '2011-01-03'\n",
    "end_dt= '2015-04-13'\n",
    "training_start_dt = '2011-01-03'\n",
    "training_end_dt = '2012-12-31'\n",
    "\n",
    "test_start_dt = '2013-01-02' \n",
    "test_end_dt = '2013-12-31'\n",
    "\n",
    "out_of_sample_start_dt = '2014-01-02'\n",
    "out_of_sample_end_dt = '2015-04-13'\n",
    "\n",
    "dia_df = Stock('DIA', start_dt, end_dt)\n",
    "# dia_df.ticker_data['ticker'] = 'diaA'\n",
    "\n",
    "spy_df= Stock('SPY',start_dt, end_dt)\n",
    "# spy_df.ticker_data['ticker'] = 'SPY'\n",
    "\n",
    "qqq_df = Stock('QQQ', start_dt, end_dt)\n",
    "# qqq_df.ticker_data['ticker'] = 'QQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>Cumulative_Percentage_Change</th>\n",
       "      <th>normalized_close</th>\n",
       "      <th>cumulative_mean_normalized_close</th>\n",
       "      <th>cumulative_variance_normalized_close</th>\n",
       "      <th>cumulative_std_normalized_close</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>Jarque_Bera_stat</th>\n",
       "      <th>Jarque_Bera_p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-03</th>\n",
       "      <td>116.410004</td>\n",
       "      <td>116.860001</td>\n",
       "      <td>116.360001</td>\n",
       "      <td>116.410004</td>\n",
       "      <td>9108900</td>\n",
       "      <td>DIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131682</td>\n",
       "      <td>0.131682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-04</th>\n",
       "      <td>116.709999</td>\n",
       "      <td>116.730003</td>\n",
       "      <td>116.110001</td>\n",
       "      <td>116.639999</td>\n",
       "      <td>9775600</td>\n",
       "      <td>DIA</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.197574</td>\n",
       "      <td>0.134696</td>\n",
       "      <td>0.133189</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-05</th>\n",
       "      <td>116.459999</td>\n",
       "      <td>117.190002</td>\n",
       "      <td>116.300003</td>\n",
       "      <td>117.040001</td>\n",
       "      <td>7567800</td>\n",
       "      <td>DIA</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.541188</td>\n",
       "      <td>0.139937</td>\n",
       "      <td>0.135439</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003411</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-06</th>\n",
       "      <td>117.139999</td>\n",
       "      <td>117.190002</td>\n",
       "      <td>116.500000</td>\n",
       "      <td>116.779999</td>\n",
       "      <td>7161600</td>\n",
       "      <td>DIA</td>\n",
       "      <td>-0.002221</td>\n",
       "      <td>0.317838</td>\n",
       "      <td>0.136530</td>\n",
       "      <td>0.135711</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-07</th>\n",
       "      <td>116.910004</td>\n",
       "      <td>117.099998</td>\n",
       "      <td>115.820000</td>\n",
       "      <td>116.570000</td>\n",
       "      <td>9249800</td>\n",
       "      <td>DIA</td>\n",
       "      <td>-0.001798</td>\n",
       "      <td>0.137442</td>\n",
       "      <td>0.133779</td>\n",
       "      <td>0.135325</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-06</th>\n",
       "      <td>176.320007</td>\n",
       "      <td>179.169998</td>\n",
       "      <td>176.089996</td>\n",
       "      <td>178.589996</td>\n",
       "      <td>6284900</td>\n",
       "      <td>DIA</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>53.414647</td>\n",
       "      <td>0.946410</td>\n",
       "      <td>0.490137</td>\n",
       "      <td>0.073307</td>\n",
       "      <td>0.270753</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-07</th>\n",
       "      <td>178.770004</td>\n",
       "      <td>179.580002</td>\n",
       "      <td>178.419998</td>\n",
       "      <td>178.419998</td>\n",
       "      <td>6011600</td>\n",
       "      <td>DIA</td>\n",
       "      <td>-0.000952</td>\n",
       "      <td>53.268613</td>\n",
       "      <td>0.944182</td>\n",
       "      <td>0.490561</td>\n",
       "      <td>0.073431</td>\n",
       "      <td>0.270982</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-08</th>\n",
       "      <td>178.600006</td>\n",
       "      <td>179.559998</td>\n",
       "      <td>177.960007</td>\n",
       "      <td>178.750000</td>\n",
       "      <td>4738500</td>\n",
       "      <td>DIA</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>53.552096</td>\n",
       "      <td>0.948506</td>\n",
       "      <td>0.490988</td>\n",
       "      <td>0.073558</td>\n",
       "      <td>0.271216</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-09</th>\n",
       "      <td>178.660004</td>\n",
       "      <td>179.630005</td>\n",
       "      <td>177.979996</td>\n",
       "      <td>179.399994</td>\n",
       "      <td>4483800</td>\n",
       "      <td>DIA</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>54.110462</td>\n",
       "      <td>0.957023</td>\n",
       "      <td>0.491422</td>\n",
       "      <td>0.073692</td>\n",
       "      <td>0.271462</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-04-10</th>\n",
       "      <td>179.669998</td>\n",
       "      <td>180.440002</td>\n",
       "      <td>179.179993</td>\n",
       "      <td>180.369995</td>\n",
       "      <td>3463600</td>\n",
       "      <td>DIA</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>54.943724</td>\n",
       "      <td>0.969733</td>\n",
       "      <td>0.491868</td>\n",
       "      <td>0.073836</td>\n",
       "      <td>0.271728</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>804.160704</td>\n",
       "      <td>2.391784e-175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1074 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Volume ticker  \\\n",
       "2011-01-03  116.410004  116.860001  116.360001  116.410004  9108900    DIA   \n",
       "2011-01-04  116.709999  116.730003  116.110001  116.639999  9775600    DIA   \n",
       "2011-01-05  116.459999  117.190002  116.300003  117.040001  7567800    DIA   \n",
       "2011-01-06  117.139999  117.190002  116.500000  116.779999  7161600    DIA   \n",
       "2011-01-07  116.910004  117.099998  115.820000  116.570000  9249800    DIA   \n",
       "...                ...         ...         ...         ...      ...    ...   \n",
       "2015-04-06  176.320007  179.169998  176.089996  178.589996  6284900    DIA   \n",
       "2015-04-07  178.770004  179.580002  178.419998  178.419998  6011600    DIA   \n",
       "2015-04-08  178.600006  179.559998  177.960007  178.750000  4738500    DIA   \n",
       "2015-04-09  178.660004  179.630005  177.979996  179.399994  4483800    DIA   \n",
       "2015-04-10  179.669998  180.440002  179.179993  180.369995  3463600    DIA   \n",
       "\n",
       "            pct_change  Cumulative_Percentage_Change  normalized_close  \\\n",
       "2011-01-03         NaN                      0.000000          0.131682   \n",
       "2011-01-04    0.001976                      0.197574          0.134696   \n",
       "2011-01-05    0.003429                      0.541188          0.139937   \n",
       "2011-01-06   -0.002221                      0.317838          0.136530   \n",
       "2011-01-07   -0.001798                      0.137442          0.133779   \n",
       "...                ...                           ...               ...   \n",
       "2015-04-06    0.007105                     53.414647          0.946410   \n",
       "2015-04-07   -0.000952                     53.268613          0.944182   \n",
       "2015-04-08    0.001850                     53.552096          0.948506   \n",
       "2015-04-09    0.003636                     54.110462          0.957023   \n",
       "2015-04-10    0.005407                     54.943724          0.969733   \n",
       "\n",
       "            cumulative_mean_normalized_close  \\\n",
       "2011-01-03                          0.131682   \n",
       "2011-01-04                          0.133189   \n",
       "2011-01-05                          0.135439   \n",
       "2011-01-06                          0.135711   \n",
       "2011-01-07                          0.135325   \n",
       "...                                      ...   \n",
       "2015-04-06                          0.490137   \n",
       "2015-04-07                          0.490561   \n",
       "2015-04-08                          0.490988   \n",
       "2015-04-09                          0.491422   \n",
       "2015-04-10                          0.491868   \n",
       "\n",
       "            cumulative_variance_normalized_close  \\\n",
       "2011-01-03                              0.000000   \n",
       "2011-01-04                              0.000002   \n",
       "2011-01-05                              0.000012   \n",
       "2011-01-06                              0.000009   \n",
       "2011-01-07                              0.000008   \n",
       "...                                          ...   \n",
       "2015-04-06                              0.073307   \n",
       "2015-04-07                              0.073431   \n",
       "2015-04-08                              0.073558   \n",
       "2015-04-09                              0.073692   \n",
       "2015-04-10                              0.073836   \n",
       "\n",
       "            cumulative_std_normalized_close      skew  kurtosis  \\\n",
       "2011-01-03                         0.000000 -0.426358  4.152463   \n",
       "2011-01-04                         0.001507 -0.426358  4.152463   \n",
       "2011-01-05                         0.003411 -0.426358  4.152463   \n",
       "2011-01-06                         0.002991 -0.426358  4.152463   \n",
       "2011-01-07                         0.002785 -0.426358  4.152463   \n",
       "...                                     ...       ...       ...   \n",
       "2015-04-06                         0.270753 -0.426358  4.152463   \n",
       "2015-04-07                         0.270982 -0.426358  4.152463   \n",
       "2015-04-08                         0.271216 -0.426358  4.152463   \n",
       "2015-04-09                         0.271462 -0.426358  4.152463   \n",
       "2015-04-10                         0.271728 -0.426358  4.152463   \n",
       "\n",
       "            Jarque_Bera_stat  Jarque_Bera_p_val  \n",
       "2011-01-03        804.160704      2.391784e-175  \n",
       "2011-01-04        804.160704      2.391784e-175  \n",
       "2011-01-05        804.160704      2.391784e-175  \n",
       "2011-01-06        804.160704      2.391784e-175  \n",
       "2011-01-07        804.160704      2.391784e-175  \n",
       "...                      ...                ...  \n",
       "2015-04-06        804.160704      2.391784e-175  \n",
       "2015-04-07        804.160704      2.391784e-175  \n",
       "2015-04-08        804.160704      2.391784e-175  \n",
       "2015-04-09        804.160704      2.391784e-175  \n",
       "2015-04-10        804.160704      2.391784e-175  \n",
       "\n",
       "[1074 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dia_df.ticker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "class Portfolio:\n",
    "    def __init__(self, tickers, start_dt, end_dt, timeframe=\"1D\", var_confidence_level=0.95, cvar_confidence_level=0.95):\n",
    "        self.stocks = {}\n",
    "        self.summary_statistics = pd.DataFrame(columns=['ticker', 'mean', 'variance', 'skewness', 'kurtosis', 'VaR', 'cVaR'])\n",
    "        self.pct_changes = pd.DataFrame()\n",
    "        self.all_stocks_df = pd.DataFrame()\n",
    "\n",
    "        for ticker in tickers:\n",
    "            stock = Stock(ticker, start_dt, end_dt, timeframe)\n",
    "            self.stocks[ticker] = stock\n",
    "\n",
    "            mean = stock.ticker_data['pct_change'].mean()\n",
    "            variance = stock.ticker_data['pct_change'].var(ddof=0)\n",
    "            skewness = stock.ticker_data['skew'].iloc[0]\n",
    "            kurtosis = stock.ticker_data['kurtosis'].iloc[0]\n",
    "\n",
    "            # Calculate VaR and cVaR\n",
    "            var = self.calculate_var(stock.ticker_data['pct_change'].dropna(), var_confidence_level)\n",
    "            cvar = self.calculate_cvar(stock.ticker_data['pct_change'].dropna(), cvar_confidence_level)\n",
    "\n",
    "            self.summary_statistics = self.summary_statistics.append({\n",
    "                'ticker': ticker,\n",
    "                'mean': mean,\n",
    "                'variance': variance,\n",
    "                'skewness': skewness,\n",
    "                'kurtosis': kurtosis,\n",
    "                'VaR': var,\n",
    "                'cVaR': cvar\n",
    "            }, ignore_index=True)\n",
    "\n",
    "            self.pct_changes[ticker] = stock.ticker_data['pct_change']\n",
    "            self.all_stocks_df = self.all_stocks_df.append(stock.ticker_data)\n",
    "\n",
    "        self.correlation_matrix = self.pct_changes.corr()\n",
    "\n",
    "    def display_summary_statistics(self):\n",
    "        print(self.summary_statistics)\n",
    "\n",
    "    def display_correlation_matrix(self):\n",
    "        print(self.correlation_matrix)\n",
    "\n",
    "    def calculate_var(self, returns, confidence_level):\n",
    "        # Calculate the Value at Risk (VaR) using the parametric method\n",
    "        mean = returns.mean()\n",
    "        std_dev = returns.std(ddof=0)\n",
    "        z_score = norm.ppf(confidence_level)\n",
    "        var = mean - z_score * std_dev\n",
    "        return var\n",
    "\n",
    "    def calculate_cvar(self, returns, confidence_level):\n",
    "        # Calculate the Conditional Value at Risk (cVaR) using the historical method\n",
    "        var = self.calculate_var(returns, confidence_level)\n",
    "        losses_below_var = returns[returns < var]\n",
    "        cvar = losses_below_var.mean()\n",
    "        return cvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data from alpaca\n",
      "Data from alpaca not available, pulling from yahoo\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "data from alpaca\n",
      "Data from alpaca not available, pulling from yahoo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/tgqd8prn2x1g474v7zwrxq7r0000gn/T/ipykernel_14411/467402769.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.summary_statistics = self.summary_statistics.append({\n",
      "/var/folders/tp/tgqd8prn2x1g474v7zwrxq7r0000gn/T/ipykernel_14411/467402769.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.all_stocks_df = self.all_stocks_df.append(stock.ticker_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "data from alpaca\n",
      "Data from alpaca not available, pulling from yahoo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/tgqd8prn2x1g474v7zwrxq7r0000gn/T/ipykernel_14411/467402769.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.summary_statistics = self.summary_statistics.append({\n",
      "/var/folders/tp/tgqd8prn2x1g474v7zwrxq7r0000gn/T/ipykernel_14411/467402769.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.all_stocks_df = self.all_stocks_df.append(stock.ticker_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tp/tgqd8prn2x1g474v7zwrxq7r0000gn/T/ipykernel_14411/467402769.py:25: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.summary_statistics = self.summary_statistics.append({\n",
      "/var/folders/tp/tgqd8prn2x1g474v7zwrxq7r0000gn/T/ipykernel_14411/467402769.py:36: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  self.all_stocks_df = self.all_stocks_df.append(stock.ticker_data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Portfolio at 0x7fcbe0100b20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Portfolio(tickers=[ 'DIA', 'QQQ', 'SPY' ], start_dt=start_dt, end_dt=end_dt)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>VaR</th>\n",
       "      <th>cVaR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIA</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>-0.426358</td>\n",
       "      <td>4.152463</td>\n",
       "      <td>-0.014124</td>\n",
       "      <td>-0.021020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QQQ</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>-0.319222</td>\n",
       "      <td>3.023044</td>\n",
       "      <td>-0.016630</td>\n",
       "      <td>-0.024192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SPY</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>-0.453330</td>\n",
       "      <td>4.917879</td>\n",
       "      <td>-0.015261</td>\n",
       "      <td>-0.022763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker      mean  variance  skewness  kurtosis       VaR      cVaR\n",
       "0    DIA  0.000448  0.000078 -0.426358  4.152463 -0.014124 -0.021020\n",
       "1    QQQ  0.000677  0.000111 -0.319222  3.023044 -0.016630 -0.024192\n",
       "2    SPY  0.000515  0.000092 -0.453330  4.917879 -0.015261 -0.022763"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.summary_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIA</th>\n",
       "      <th>QQQ</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DIA</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871865</td>\n",
       "      <td>0.971892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QQQ</th>\n",
       "      <td>0.871865</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.926446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SPY</th>\n",
       "      <td>0.971892</td>\n",
       "      <td>0.926446</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DIA       QQQ       SPY\n",
       "DIA  1.000000  0.871865  0.971892\n",
       "QQQ  0.871865  1.000000  0.926446\n",
       "SPY  0.971892  0.926446  1.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Portfolio at 0x7fcbe0100b20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.all_stocks_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (371449011.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [10]\u001b[0;36m\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dia_df.ticker_data, spy_df.ticker_data, qqq_df.ticker_data])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_column_across_tickers(df, col_name = 'Close', title='Closing Price across ETFs', yaxis_title='Closing Price (USD)', xaxis_title='Trading Date')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_column_across_tickers(df, col_name = 'Cumulative_Percentage_Change', title='Cumulative Percentage Change of Closing Price', xaxis_title='Trading Date', yaxis_title='Cumulative % increase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_column_across_tickers(df, col_name = 'Close', title='Cumulative Percentage Change of Closing Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_column_across_tickers(df, col_name = 'normalized_close', title='Normalized Closing Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_column_across_tickers(df, col_name = 'cumulative_mean_normalized_close', title='cumulative_mean_normalized_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_column_across_tickers(df, col_name = 'cumulative_variance_normalized_close', title='cumulative_variance_normalized_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_column_across_tickers(df, col_name = 'cumulative_std_normalized_close', title='cumulative_std_normalized_close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [list(dia_df.ticker_data.index),list(spy_df.ticker_data.index),list(qqq_df.ticker_data.index)]\n",
    "y_data = [list(dia_df.ticker_data['pct_change']), list(spy_df.ticker_data['pct_change']), list(qqq_df.ticker_data['pct_change'])]\n",
    "\n",
    "plot.plot_multi_line_chart(x_data, y_data, labels=['DIA', 'SPY', 'QQQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "agg_stats_df = []\n",
    "tickers = list(df['ticker'].unique())\n",
    "\n",
    "for i in range(0,len(tickers)):\n",
    "    temp_df = df[df['ticker']==tickers[i]]\n",
    "    \n",
    "    \n",
    "\n",
    "    price_data = temp_df['Close']\n",
    "    returns = (price_data / price_data.shift(1)) - 1\n",
    "    returns = returns.iloc[1:]\n",
    "    \n",
    "    VaR = rt.historical_var(returns, confidence_level=0.95)\n",
    "    cVaR = rt.historical_cvar(returns, confidence_level=0.95)\n",
    "    \n",
    "    print(f\"Historical VaR :{VaR}\")\n",
    "    print(f\"Historical cVaR :{cVaR}\")\n",
    "\n",
    "    agg_stats_df.append(pd.DataFrame({'ticker':[tickers[i]], 'mean':[temp_df['normalized_close'].mean()], 'std_dev':[temp_df['normalized_close'].std()], \\\n",
    "                                     'VaR':[VaR], 'cVaR':[cVaR]}))\n",
    "    \n",
    "agg_stats_df = pd.concat(agg_stats_df)\n",
    "agg_stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_markowitz_bullet(list(agg_stats_df['std_dev']), list(agg_stats_df['mean']), text_vals =list(agg_stats_df['ticker']),  title='Markowitz Bullet', xaxis_title='Risk', yaxis_title='Return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_markowitz_bullet(list(agg_stats_df['VaR']), list(agg_stats_df['mean']), text_vals =list(agg_stats_df['ticker']),  title='Markowitz Bullet using VaR as measure of Risk', xaxis_title='Risk', yaxis_title='Return')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_markowitz_bullet(list(agg_stats_df['cVaR']), list(agg_stats_df['mean']), text_vals =list(agg_stats_df['ticker']),  title='Markowitz Bullet by cVaR as a measure of Risk', xaxis_title='Risk', yaxis_title='Return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bound, mean, high_bound = dt.get_confidence_interval(dia_df.ticker_data, 'pct_change', conf_interval=95)\n",
    "low_bound, mean, high_bound "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bound, mean, high_bound = dt.get_confidence_interval(spy_df.ticker_data, 'pct_change', conf_interval=95)\n",
    "low_bound, mean, high_bound "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_bound, mean, high_bound = dt.get_confidence_interval(qqq_df.ticker_data, 'pct_change', conf_interval=95)\n",
    "low_bound, mean, high_bound "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_df = Stock('DIA', start_dt, end_dt)\n",
    "# dia_df.ticker_data['ticker'] = 'diaA'\n",
    "\n",
    "spy_df= Stock('SPY', start_dt, end_dt)\n",
    "# spy_df.ticker_data['ticker'] = 'SPY'\n",
    "\n",
    "qqq_df = Stock('QQQ', start_dt, end_dt)\n",
    "# qqq_df.ticker_data['ticker'] = 'QQQ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [dia_df.ticker_data,spy_df.ticker_data, qqq_df.ticker_data]\n",
    "\n",
    "\n",
    "def merge_dfs(dfs): \n",
    "\n",
    "    merged_df = dfs[0].copy(deep=True)\n",
    "    ticker = merged_df['ticker'].iloc[0]\n",
    "    merged_df.rename(columns={'Close':f'Close_{ticker}'}, inplace=True)\n",
    "\n",
    "    for i in range(1,len(dfs)): \n",
    "        temp_df =dfs[i].copy(deep=True)\n",
    "        temp_ticker = temp_df['ticker'].iloc[0]\n",
    "        temp_df.rename(columns={'Close':f'Close_{temp_ticker}'}, inplace=True)\n",
    "\n",
    "\n",
    "        merged_df = pd.merge(merged_df, temp_df, left_index=True, right_index=True)\n",
    "        \n",
    "    return merged_df \n",
    "    \n",
    "merged_df =merge_dfs(dfs)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dia_df.ticker_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrelevant_cols = [col for col in merged_df.columns if any(x in col.lower() for x in ['open', 'high', 'low', 'volume'])]\n",
    "irrelevant_cols\n",
    "\n",
    "merged_df.drop(columns=irrelevant_cols, inplace=True)\n",
    "close_cols = [f'Close_{ticker}' for ticker in tickers]\n",
    "close_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[close_cols]\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations(step=0.2, target_sum=1.0, num_variables=3, precision=1):\n",
    "    combinations = []\n",
    "    num_steps = int(target_sum / step) + 1\n",
    "\n",
    "    for i in range(num_steps):\n",
    "        for j in range(num_steps - i):\n",
    "            k = num_steps - i - j - 1\n",
    "            if round(i * step, precision) + round(j * step, precision) + round(k * step, precision) == target_sum:\n",
    "                combinations.append((round(i * step, precision), round(j * step, precision), round(k * step, precision)))\n",
    "\n",
    "    return combinations\n",
    "\n",
    "combinations = generate_combinations()\n",
    "print(combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i =7\n",
    "combination = combinations[i]\n",
    "combination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation of Portfolio performance under naive weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_budget =10000\n",
    "\n",
    "def simulate_portfolio_value(input_df, combination): \n",
    "\n",
    "    for i in range(0,len(combination)): \n",
    "        input_df[f'weight_{tickers[i]}'] = combination[i]\n",
    "\n",
    "    for ticker in tickers: \n",
    "        input_df[f'{ticker}_num_stocks'] = initial_budget*input_df[f'weight_{ticker}'].iloc[0]/input_df[f'Close_{ticker}'].iloc[0]\n",
    "\n",
    "    portfolio_values = []\n",
    "    for i in range(0,len(input_df)): \n",
    "        portfolio_value = 0\n",
    "        for ticker in tickers: \n",
    "            portfolio_value+= input_df[f'Close_{ticker}'].iloc[i] * input_df[f'{ticker}_num_stocks'].iloc[0]\n",
    "        portfolio_values.append(portfolio_value)\n",
    "    portfolio_values\n",
    "\n",
    "    input_df['portfolio_value'] = portfolio_values\n",
    "\n",
    "    return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "simulated_portfolio_values = []\n",
    "for i in range(0,len(combinations)): \n",
    "    simulated_portfolio_values.append((combinations[i], simulate_portfolio_value(merged_df, combinations[i])['portfolio_value']))\n",
    "simulated_portfolio_values\n",
    "\n",
    "for i in range(0,len(simulated_portfolio_values)): \n",
    "    plt.plot(pd.to_datetime(simulated_portfolio_values[i][1].index), simulated_portfolio_values[i][1].values, label=str(simulated_portfolio_values[i][0]))\n",
    "    \n",
    "    \n",
    "plt.axhline(y=10000, color='r',  ls='--', label=f'simulated initial budget of ${initial_budget}')\n",
    "\n",
    "plt.legend(loc='upper right', title='Weights for dia, SPY and QQQ resp.', bbox_to_anchor=(1.2, 1.0))\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(f\"Simulation of portfolio value under different weights for stocks dia, SPY and QQQ from {start_dt} to {end_dt}\", fontsize=20)\n",
    "plt.xlabel(\"Trading Date\")\n",
    "plt.ylabel(\"Portfolio Value in USD $\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "simulated_portfolio_values_df_list = []\n",
    "\n",
    "simulated_portfolio_values[i]\n",
    "\n",
    "for i in range(0,len(simulated_portfolio_values)): \n",
    "    \n",
    "    price_data =simulated_portfolio_values[i][1]\n",
    "    returns = (price_data / price_data.shift(1)) - 1\n",
    "    returns = returns.iloc[1:]\n",
    "    VaR = rt.historical_var(returns, confidence_level=0.95)\n",
    "    cVaR = rt.historical_cvar(returns, confidence_level=0.95)\n",
    "    \n",
    "    simulated_portfolio_values_df_list.append(pd.DataFrame({'portfolio_config':[str(simulated_portfolio_values[i][0])], \\\n",
    "                                                            'mean':[np.mean(simulated_portfolio_values[i][1])], \\\n",
    "                                                            'var':[np.var(simulated_portfolio_values[i][1])], \\\n",
    "                                                            'std':[np.std(simulated_portfolio_values[i][1])],\\\n",
    "                                                            'VaR':[VaR], 'cVaR':[cVaR]\n",
    "                                                           }))\n",
    "    \n",
    "simulated_portfolio_values_df = pd.concat(simulated_portfolio_values_df_list)\n",
    "simulated_portfolio_values_df['net_return'] = (simulated_portfolio_values_df['mean']-initial_budget)/initial_budget\n",
    "simulated_portfolio_values_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_markowitz_bullet(list(simulated_portfolio_values_df['var']), list(simulated_portfolio_values_df['net_return']), \\\n",
    "                           text_vals =list(simulated_portfolio_values_df['portfolio_config']), \\\n",
    "                           title='Markowitz Bullet for different portfolios under diff weights for (diaA, SPY, QQQ)',\\\n",
    "                           xaxis_title='Variance(Risk)', yaxis_title='Return from initial investment (%)', height=600, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_markowitz_bullet(list(simulated_portfolio_values_df['std']), list(simulated_portfolio_values_df['net_return']), \\\n",
    "                           text_vals =list(simulated_portfolio_values_df['portfolio_config']), \\\n",
    "                           title='Markowitz Bullet for different portfolios under diff weights for (diaA, SPY, QQQ)',\\\n",
    "                           xaxis_title='Standard Deviation (Risk)', yaxis_title='Return from initial investment (%)', height=600, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_markowitz_bullet(list(simulated_portfolio_values_df['VaR']), list(simulated_portfolio_values_df['net_return']), \\\n",
    "                           text_vals =list(simulated_portfolio_values_df['portfolio_config']), \\\n",
    "                           title='Markowitz Bullet (VaR) for different portfolios under diff weights for (diaA, SPY, QQQ)',\\\n",
    "                           xaxis_title='Standard Deviation (Risk)', yaxis_title='Return from initial investment (%)', height=600, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot_markowitz_bullet(list(simulated_portfolio_values_df['cVaR']), list(simulated_portfolio_values_df['net_return']), \\\n",
    "                           text_vals =list(simulated_portfolio_values_df['portfolio_config']), \\\n",
    "                           title='Markowitz Bullet (cVaR) for different portfolios under diff weights for (diaA, SPY, QQQ)',\\\n",
    "                           xaxis_title='Standard Deviation (Risk)', yaxis_title='Return from initial investment (%)', height=600, width=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import plotly.graph_objects as go\n",
    "\n",
    "# def multiline_plot(df, columns, labels=None):\n",
    "#     \"\"\"\n",
    "#     Creates a multiline plot using Plotly.\n",
    "\n",
    "#     Args:\n",
    "#     df (pd.DataFrame): The input DataFrame.\n",
    "#     columns (list): A list of column names to plot.\n",
    "#     labels (list, optional): A list of labels corresponding to the columns. Default is None, in which case column names are used.\n",
    "\n",
    "#     Returns:\n",
    "#     plotly.graph_objects.Figure: The multiline plot figure.\n",
    "#     \"\"\"\n",
    "\n",
    "#     if labels is None:\n",
    "#         labels = columns\n",
    "\n",
    "#     assert len(columns) == len(labels), \"The number of columns and labels must be equal.\"\n",
    "\n",
    "#     fig = go.Figure()\n",
    "\n",
    "#     for col, label in zip(columns, labels):\n",
    "#         fig.add_trace(go.Scatter(x=df.index, y=df[col], name=label, mode='lines'))\n",
    "\n",
    "#     fig.update_layout(title='Multiline Plot', xaxis_title='Date', yaxis_title='Values')\n",
    "\n",
    "#     return fig\n",
    "\n",
    "# Example usage\n",
    "columns_to_plot = ['Close_DIA', 'Close_SPY', 'Close_QQQ', 'portfolio_value']\n",
    "labels = ['dia',  'NASDAQ', 'S&P 500','portfolio value']\n",
    "\n",
    "fig = plot.multiline_plot(merged_df, columns_to_plot, labels)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting Using Facebook Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dia_df.ticker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph.plot_prediction(dia_df, ticker='DIA', test_period=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph.plot_prediction(qqq_df, ticker='QQQ', test_period=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph.plot_prediction(spy_df, ticker='SPY', test_period=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "data = np.random.normal(0, 1, 1000)  # Generate a sample normal distribution\n",
    "dt.generate_qq_plot_normal(data, title='Theoretical Perfect Gaussian', label='Artificial Perfect Gaussian')\n",
    "\n",
    "dt.generate_qq_plot_normal(spy_df.ticker_data['pct_change'], title='QQ plot on SPY', label='SPY returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.generate_qq_plot_normal(dia_df.ticker_data['pct_change'], title='QQ plot on dia', label='dia returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.generate_qq_plot_normal(qqq_df.ticker_data['pct_change'], title='QQ plot on QQQ ETF', label='QQQ returns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
